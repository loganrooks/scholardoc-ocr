name: Benchmark

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

jobs:
  benchmark:
    runs-on: macos-14  # Apple Silicon (M-series) runner
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          brew install tesseract tesseract-lang

      - name: Install package with dev dependencies
        run: |
          pip install -e ".[dev]"

      - name: Run benchmarks
        run: |
          # Run benchmarks, skip if Surya not available
          pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-group-by=func \
            -v || echo "Benchmarks skipped or completed"

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: always() && hashFiles('benchmark-results.json') != ''
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Store results in gh-pages branch for historical tracking
          auto-push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
          # Alert and fail if 50% regression (150% of baseline)
          alert-threshold: '150%'
          fail-on-alert: true
          comment-on-alert: true
          # Save results even on PR (for comparison)
          save-data-file: ${{ github.event_name == 'push' }}

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        if: always() && hashFiles('benchmark-results.json') != ''
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30
