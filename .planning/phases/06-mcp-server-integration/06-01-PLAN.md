---
phase: 06-mcp-server-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/mcp_server.py
  - pyproject.toml
autonomous: true

must_haves:
  truths:
    - "OCR pipeline callable as MCP tool from Claude Desktop via stdio transport"
    - "Tool returns structured metadata dict (no full text in response)"
    - "extract_text=true writes .txt file alongside output PDF; response includes path only"
    - "page_range parameter (e.g. '45-80') extracts and OCRs only those pages"
    - "output_name parameter renames the output file"
    - "No existing library modules are modified"
  artifacts:
    - path: "src/scholardoc_ocr/mcp_server.py"
      provides: "MCP server with ocr tool"
      contains: "FastMCP"
    - path: "pyproject.toml"
      provides: "mcp optional dependency and entry point"
      contains: "scholardoc-ocr-mcp"
  key_links:
    - from: "src/scholardoc_ocr/mcp_server.py"
      to: "pipeline.run_pipeline"
      via: "lazy import + asyncio.to_thread"
      pattern: "asyncio\\.to_thread.*run_pipeline"
    - from: "pyproject.toml"
      to: "src/scholardoc_ocr/mcp_server.py"
      via: "entry point"
      pattern: "scholardoc_ocr\\.mcp_server:main"
---

<objective>
Create MCP server module exposing the OCR pipeline as a tool for Claude Desktop.

Purpose: Enable conversational OCR processing — Claude can OCR files on request without the user switching to CLI.
Output: `mcp_server.py` module with one `ocr` tool, updated `pyproject.toml` with optional `mcp` dependency and entry point.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-mcp-server-integration/06-RESEARCH.md
@src/scholardoc_ocr/types.py
@src/scholardoc_ocr/pipeline.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add MCP optional dependency and entry point to pyproject.toml</name>
  <files>pyproject.toml</files>
  <action>
Add an `mcp` optional dependency group and a new script entry point:

1. In `[project.optional-dependencies]`, add:
```toml
mcp = ["mcp[cli]"]
```

2. In `[project.scripts]`, add:
```toml
scholardoc-ocr-mcp = "scholardoc_ocr.mcp_server:main"
```

3. Run `pip install -e ".[mcp]"` to install the MCP dependency.
  </action>
  <verify>
`pip install -e ".[mcp]"` succeeds. `python -c "from mcp.server.fastmcp import FastMCP; print('ok')"` prints "ok".
  </verify>
  <done>pyproject.toml has mcp optional dep and scholardoc-ocr-mcp entry point; mcp SDK importable.</done>
</task>

<task type="auto">
  <name>Task 2: Create mcp_server.py with ocr tool</name>
  <files>src/scholardoc_ocr/mcp_server.py</files>
  <action>
Create `src/scholardoc_ocr/mcp_server.py` with a single `ocr` tool. Follow the research findings exactly. Key requirements:

**Tool parameters:**
- `input_path: str` — Path to a directory or single PDF file. Expand `~`, resolve to absolute, validate existence.
- `quality_threshold: float = 0.85` — Quality threshold for Surya fallback.
- `force_surya: bool = False` — Force Surya OCR on all pages.
- `max_workers: int = 4` — Max parallel Tesseract workers.
- `extract_text: bool = False` — If true, read text from OCR'd PDF via PyMuPDF, write to .txt file alongside output. Include .txt path in response but NOT the text content.
- `page_range: str | None = None` — e.g. "45-80". If provided, extract those pages into a temp PDF via PyMuPDF before OCR, then OCR only those pages. Parse as "{start}-{end}" (1-based inclusive).
- `output_name: str | None = None` — If provided, rename the output PDF to this name after pipeline completes.

**Implementation details:**

1. `mcp = FastMCP("scholardoc-ocr")` at module level.

2. Lazy imports: `from .pipeline import run_pipeline` and `from .types import PipelineConfig` inside the tool function, NOT at module level. Same for `fitz` (PyMuPDF).

3. Path handling: `Path(input_path).expanduser().resolve()`. If single file, set `config.files = [path]` and `config.input_dir = path.parent`. If directory, set `config.input_dir = path`.

4. Output dir: `input_path_resolved.parent / "scholardoc_ocr"` for single file, `input_path_resolved / "scholardoc_ocr"` for directory.

5. Run pipeline with `await asyncio.to_thread(run_pipeline, config)` to avoid blocking the event loop.

6. After pipeline completes, get result via `result.to_dict(include_text=False)`.

7. **page_range pre-processing** (MCP-04): If page_range provided:
   - Parse "{start}-{end}" (1-based). Return error dict if invalid format.
   - Open the source PDF with `fitz.open()`, extract pages (0-based: start-1 to end-1 inclusive).
   - Write extracted pages to a temp file in the same directory as the source (e.g. `{stem}_pages_{start}-{end}.pdf`).
   - Set the pipeline to process this temp file instead.
   - After pipeline completes, clean up the temp source file (keep the OCR'd output).

8. **extract_text post-processing** (MCP-03): If extract_text is true:
   - For each output file in the result, open with `fitz.open()`, extract all text page by page.
   - Write to `{output_path_stem}.txt` alongside the output PDF.
   - Add `"text_file": str(txt_path)` to the result dict for each file.
   - Do NOT include the text content in the response dict.

9. **output_name post-processing** (MCP-05): If output_name is provided:
   - Only applies when processing a single file (return error if multiple files and output_name given).
   - Rename the output PDF from its default name to output_name in the same output directory.
   - Update the result dict path accordingly.

10. `def main(): mcp.run()` entry point.

11. `if __name__ == "__main__": main()` guard.

**Error handling:** Wrap the tool body in try/except. On any exception, return `{"error": str(e)}` dict instead of raising (MCP tools should return errors as data, not crash).

**Docstring:** Write a clear docstring on the `ocr` function — FastMCP uses it to generate the tool description shown to Claude.
  </action>
  <verify>
1. `ruff check src/scholardoc_ocr/mcp_server.py` passes with no errors.
2. `ruff format --check src/scholardoc_ocr/mcp_server.py` passes.
3. `python -c "from scholardoc_ocr.mcp_server import mcp; print(mcp.name)"` prints "scholardoc-ocr".
4. `python -c "from scholardoc_ocr.mcp_server import main; print('ok')"` prints "ok" (does not start server).
  </verify>
  <done>
mcp_server.py exists with ocr tool supporting all 5 MCP requirements (MCP-01 through MCP-05). Linting passes. Module importable without loading ML models. No existing library files modified.
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/mcp_server.py` — no lint errors
2. `ruff format --check src/scholardoc_ocr/mcp_server.py` — properly formatted
3. `python -c "from scholardoc_ocr.mcp_server import mcp; print(mcp.name)"` — prints "scholardoc-ocr"
4. `git diff --name-only` — only mcp_server.py (new) and pyproject.toml (modified), no changes to existing library modules
5. `grep "scholardoc-ocr-mcp" pyproject.toml` — entry point exists
6. `grep 'mcp\[cli\]' pyproject.toml` — optional dependency exists
</verification>

<success_criteria>
- MCP server module exists and is importable without triggering ML model loads
- Single `ocr` tool with all required parameters (input_path, quality_threshold, force_surya, max_workers, extract_text, page_range, output_name)
- Pipeline called via asyncio.to_thread (non-blocking)
- Returns structured metadata only (no text content in response)
- extract_text writes .txt file, returns path
- page_range extracts pages before OCR
- output_name renames output after OCR
- pyproject.toml has mcp optional dep and entry point
- No existing library files modified
- Lint clean
</success_criteria>

<output>
After completion, create `.planning/phases/06-mcp-server-integration/06-01-SUMMARY.md`
</output>
