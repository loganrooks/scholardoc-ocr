---
phase: 12-device-configuration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/device.py
  - src/scholardoc_ocr/types.py
autonomous: true

must_haves:
  truths:
    - "load_models_with_fallback() loads Marker models on preferred device"
    - "On OOM or device failure, automatically falls back to CPU"
    - "strict_gpu=True raises RuntimeError instead of falling back"
    - "Result metadata includes device_used field"
  artifacts:
    - path: "src/scholardoc_ocr/device.py"
      provides: "Model loading with device fallback"
      exports: ["load_models_with_fallback"]
      contains: "def load_models_with_fallback"
    - path: "src/scholardoc_ocr/types.py"
      provides: "Device tracking in FileResult"
      contains: "device_used"
  key_links:
    - from: "src/scholardoc_ocr/device.py"
      to: "marker.models.create_model_dict"
      via: "model loading call"
      pattern: "create_model_dict"
---

<objective>
Add model loading with device fallback and result metadata tracking.

Purpose: Enable GPU-accelerated model loading with graceful fallback to CPU when GPU fails,
         and track which device was actually used for transparency.

Output: load_models_with_fallback() function and device_used field in FileResult.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-device-configuration/12-RESEARCH.md

Reference existing surya.py for Marker integration pattern:
@src/scholardoc_ocr/surya.py
@src/scholardoc_ocr/types.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add load_models_with_fallback to device.py</name>
  <files>src/scholardoc_ocr/device.py</files>
  <action>
Add to device.py:

1. LoadResult dataclass:
   - model_dict: dict[str, Any]
   - device_info: DeviceInfo
   - fallback_occurred: bool

2. load_models_with_fallback() function:
   ```python
   def load_models_with_fallback(
       device_info: DeviceInfo | None = None,
       strict_gpu: bool = False,
   ) -> LoadResult:
   ```

   Logic:
   - If device_info is None, call detect_device() to get it
   - Try to load models on device_info.device_type using create_model_dict()
   - On RuntimeError (including OOM):
     a. If strict_gpu=True, re-raise with clear message
     b. Log WARNING: "Failed to load models on {device}, falling back to CPU: {error}"
     c. Retry with device="cpu"
     d. Set fallback_occurred=True and update device_info.fallback_from
   - On success, sync GPU (mps_sync or cuda_sync) before returning
   - Return LoadResult with model_dict, device_info, fallback_occurred

3. Lazy imports:
   - Import torch inside function
   - Import create_model_dict inside function
   - Use timing.mps_sync() for synchronization (already handles MPS availability check)

Key pattern from RESEARCH.md:
- OOM recovery MUST happen outside except block (Python exception holds stack frame reference)
  </action>
  <verify>
Run: python -c "from scholardoc_ocr.device import load_models_with_fallback; r = load_models_with_fallback(); print(f'Device: {r.device_info.device_type}, fallback: {r.fallback_occurred}')"

Note: This test loads actual models and takes 30-60 seconds. Only run if needed.
  </verify>
  <done>
load_models_with_fallback() exists and handles device fallback with proper OOM recovery pattern
  </done>
</task>

<task type="auto">
  <name>Task 2: Add device_used field to FileResult</name>
  <files>src/scholardoc_ocr/types.py</files>
  <action>
Modify FileResult dataclass in types.py:

1. Add new field after output_path:
   ```python
   device_used: str | None = None  # Device that processed this file (cuda/mps/cpu)
   ```

2. Update to_dict() method to include device_used:
   ```python
   if self.device_used is not None:
       d["device_used"] = self.device_used
   ```

This provides transparency about which device processed each file, useful for:
- Debugging performance issues
- Validating GPU acceleration is working
- Understanding fallback behavior
  </action>
  <verify>
Run: python -c "from scholardoc_ocr.types import FileResult, OCREngine, PageStatus; f = FileResult(filename='test.pdf', success=True, engine=OCREngine.TESSERACT, quality_score=0.9, page_count=1, pages=[], device_used='mps'); print(f.to_dict())"

Expected: Output includes "device_used": "mps"
  </verify>
  <done>
FileResult includes device_used field and serializes it in to_dict()
  </done>
</task>

<task type="auto">
  <name>Task 3: Add tests for model loading with fallback</name>
  <files>tests/test_device.py</files>
  <action>
Add to tests/test_device.py:

1. Test LoadResult dataclass exists with correct fields

2. Test load_models_with_fallback with mock (don't actually load models):
   - Mock create_model_dict to return empty dict
   - Verify LoadResult has device_info and model_dict
   - Verify fallback_occurred defaults to False on success

3. Test strict_gpu=True raises RuntimeError when mock fails:
   - Mock create_model_dict to raise RuntimeError
   - Verify RuntimeError is raised (not swallowed)
   - Verify error message mentions strict_gpu

4. Test fallback behavior with mock:
   - Mock create_model_dict to fail first time, succeed second time
   - Verify fallback_occurred=True
   - Verify device_info.fallback_from is set

Use pytest.fixture for mocks:
   ```python
   @pytest.fixture
   def mock_create_model_dict(monkeypatch):
       # Mock marker.models.create_model_dict
   ```
  </action>
  <verify>
Run: pytest tests/test_device.py -v -k "load_models"

Expected: All load_models tests pass
  </verify>
  <done>
Unit tests verify model loading with fallback behavior using mocks
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/device.py src/scholardoc_ocr/types.py` - no lint errors
2. `ruff format --check src/scholardoc_ocr/device.py src/scholardoc_ocr/types.py` - properly formatted
3. `pytest tests/test_device.py -v` - all tests pass
4. `pytest tests/test_types.py -v` - existing types tests still pass (if they exist)
</verification>

<success_criteria>
- load_models_with_fallback() handles device failures gracefully
- strict_gpu=True prevents fallback (fails fast for debugging)
- OOM recovery happens outside except block per PyTorch best practice
- FileResult.device_used tracks which device processed each file
- DEV-03 requirements met (automatic CPU fallback)
</success_criteria>

<output>
After completion, create `.planning/phases/12-device-configuration/12-02-SUMMARY.md`
</output>
