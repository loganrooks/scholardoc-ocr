---
phase: 12-device-configuration
plan: 05
type: execute
wave: 3
depends_on: ["12-03", "12-04"]
files_modified:
  - src/scholardoc_ocr/surya.py
  - src/scholardoc_ocr/pipeline.py
  - tests/test_device.py
autonomous: true

must_haves:
  truths:
    - "Surya OCR attempts MPS/CUDA first, falls back to CPU on failure"
    - "On inference failure, entire batch is retried on CPU (not partial)"
    - "Fallback is logged at WARNING with specific error message"
    - "strict_gpu=True causes failure instead of fallback"
  artifacts:
    - path: "src/scholardoc_ocr/surya.py"
      provides: "Inference with device fallback"
      contains: "def convert_pdf_with_fallback"
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Pipeline uses convert_pdf_with_fallback"
      contains: "convert_pdf_with_fallback"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/surya.py"
      via: "convert_pdf_with_fallback call"
      pattern: "convert_pdf_with_fallback"
---

<objective>
Implement inference-time fallback from GPU to CPU for Surya OCR.

Purpose: Handle MPS bugs and GPU failures gracefully by retrying the entire
         conversion on CPU when GPU inference fails, ensuring processing
         completes even when GPU is problematic.

Output: convert_pdf_with_fallback() function and pipeline integration.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-device-configuration/12-RESEARCH.md
@.planning/phases/12-device-configuration/12-03-SUMMARY.md
@.planning/phases/12-device-configuration/12-04-SUMMARY.md

Reference current implementations:
@src/scholardoc_ocr/surya.py
@src/scholardoc_ocr/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add convert_pdf_with_fallback to surya.py</name>
  <files>src/scholardoc_ocr/surya.py</files>
  <action>
Add to surya.py:

1. New function convert_pdf_with_fallback():
   ```python
   def convert_pdf_with_fallback(
       input_path: Path,
       model_dict: dict[str, Any],
       config: SuryaConfig | None = None,
       page_range: list[int] | None = None,
       strict_gpu: bool = False,
   ) -> tuple[str, bool]:
       """Convert PDF with fallback from GPU to CPU on failure.

       If GPU inference fails (MPS/CUDA error, OOM), reloads models on CPU
       and retries the entire conversion. This handles known MPS bugs in
       the detection model.

       Args:
           input_path: Path to the input PDF file.
           model_dict: Pre-loaded model dictionary.
           config: Surya configuration.
           page_range: Optional list of page indices.
           strict_gpu: If True, don't fall back to CPU on failure.

       Returns:
           Tuple of (markdown_text, fallback_occurred).

       Raises:
           SuryaError: If conversion fails and strict_gpu=True, or if
                       CPU fallback also fails.
       """
   ```

   Implementation:
   - Declare `fallback_needed = False` before try block
   - Try convert_pdf() with provided model_dict
   - On RuntimeError:
     a. If strict_gpu: re-raise with SuryaError explaining GPU required
     b. Set `fallback_needed = True` and capture error message
   - OUTSIDE except block (critical for OOM recovery):
     ```python
     if fallback_needed:
         # Clear GPU memory before CPU retry
         try:
             import torch
             if torch.backends.mps.is_available():
                 torch.mps.empty_cache()
             if torch.cuda.is_available():
                 torch.cuda.empty_cache()
         except Exception:
             pass

         logger.warning(
             "GPU inference failed, retrying on CPU: %s",
             error_message,
         )
         cpu_model_dict = load_models(device="cpu")
         markdown = convert_pdf(input_path, cpu_model_dict, config, page_range)
         return markdown, True
     ```
   - Return (markdown, False) on successful GPU path

2. Keep convert_pdf() unchanged - it's the low-level function
   convert_pdf_with_fallback() is the high-level wrapper with retry logic

Note: This approach reloads models on CPU for fallback, which takes time.
This is acceptable because fallback should be rare (MPS bugs, OOM).
  </action>
  <verify>
Run: python -c "from scholardoc_ocr.surya import convert_pdf_with_fallback; print('Function exists')"

Expected: Prints "Function exists" without import errors
  </verify>
  <done>
convert_pdf_with_fallback() exists with GPU-to-CPU fallback and OOM recovery outside except block
  </done>
</task>

<task type="auto">
  <name>Task 2: Update pipeline to use convert_pdf_with_fallback</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Modify run_pipeline() in pipeline.py:

1. Import the new function:
   ```python
   from . import surya
   # surya.convert_pdf_with_fallback will be available
   ```

2. Update the Surya conversion section (around line 424):
   Replace:
   ```python
   surya_markdown = surya.convert_pdf(
       input_path, model_dict, config=surya_cfg,
       page_range=bad_indices,
   )
   ```
   With:
   ```python
   surya_markdown, fallback_occurred = surya.convert_pdf_with_fallback(
       input_path, model_dict, config=surya_cfg,
       page_range=bad_indices,
       strict_gpu=config.strict_gpu,
   )
   if fallback_occurred:
       logger.warning(
           "%s: GPU fallback occurred, processed on CPU",
           file_result.filename,
       )
       # Update device_used to reflect actual device
       file_result.device_used = "cpu"
   ```

3. Update the device_used assignment:
   - If fallback_occurred: set to "cpu"
   - Otherwise: use the device_used from load_models

4. Log the fallback in phase_timings for debugging:
   ```python
   if fallback_occurred:
       file_result.phase_timings["surya_fallback"] = True
   ```
  </action>
  <verify>
Run: pytest tests/test_pipeline.py -v -k "test_" --no-header -q 2>&1 | head -20

Expected: Existing pipeline tests still pass
  </verify>
  <done>
Pipeline uses convert_pdf_with_fallback() and tracks fallback in results
  </done>
</task>

<task type="auto">
  <name>Task 3: Add tests for inference fallback</name>
  <files>tests/test_device.py</files>
  <action>
Add to tests/test_device.py:

1. Test convert_pdf_with_fallback exists:
   ```python
   def test_convert_pdf_with_fallback_exists():
       from scholardoc_ocr.surya import convert_pdf_with_fallback
       assert callable(convert_pdf_with_fallback)
   ```

2. Test fallback behavior with mock:
   ```python
   def test_convert_pdf_with_fallback_falls_back_on_error(tmp_path, monkeypatch):
       """Verify fallback to CPU when GPU conversion fails."""
       from scholardoc_ocr import surya

       # Create a minimal mock PDF path
       pdf_path = tmp_path / "test.pdf"
       pdf_path.touch()

       # Track which device was used
       calls = []

       def mock_convert_pdf(input_path, model_dict, config=None, page_range=None):
           device = model_dict.get("_test_device", "unknown")
           calls.append(device)
           if device != "cpu":
               raise RuntimeError("Mock GPU failure")
           return "mock markdown"

       def mock_load_models(device=None):
           return {"_test_device": device or "gpu"}, device or "gpu"

       monkeypatch.setattr(surya, "convert_pdf", mock_convert_pdf)
       monkeypatch.setattr(surya, "load_models", mock_load_models)

       model_dict = {"_test_device": "gpu"}
       markdown, fallback = surya.convert_pdf_with_fallback(
           pdf_path, model_dict, strict_gpu=False
       )

       assert fallback is True
       assert markdown == "mock markdown"
       assert "cpu" in calls  # Should have retried on CPU
   ```

3. Test strict_gpu raises error:
   ```python
   def test_convert_pdf_with_fallback_strict_gpu_raises(tmp_path, monkeypatch):
       """Verify strict_gpu=True raises instead of falling back."""
       from scholardoc_ocr import surya
       from scholardoc_ocr.exceptions import SuryaError

       pdf_path = tmp_path / "test.pdf"
       pdf_path.touch()

       def mock_convert_pdf(*args, **kwargs):
           raise RuntimeError("Mock GPU failure")

       monkeypatch.setattr(surya, "convert_pdf", mock_convert_pdf)

       model_dict = {}
       with pytest.raises(SuryaError):
           surya.convert_pdf_with_fallback(
               pdf_path, model_dict, strict_gpu=True
           )
   ```
  </action>
  <verify>
Run: pytest tests/test_device.py -v -k "convert_pdf_with_fallback"

Expected: All fallback tests pass
  </verify>
  <done>
Tests verify convert_pdf_with_fallback behavior including fallback and strict_gpu
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/surya.py src/scholardoc_ocr/pipeline.py` - no lint errors
2. `ruff format --check src/scholardoc_ocr/surya.py src/scholardoc_ocr/pipeline.py` - properly formatted
3. `pytest tests/test_device.py -v` - all tests pass
4. `pytest tests/test_pipeline.py -v` - existing pipeline tests pass
</verification>

<success_criteria>
- convert_pdf_with_fallback() handles GPU failures with CPU retry
- OOM recovery happens outside except block (critical for memory cleanup)
- strict_gpu=True prevents fallback for debugging/performance testing
- Pipeline tracks fallback in results for transparency
- DEV-03 fully implemented (automatic CPU fallback on failure)
- DEV-04 implemented via full-CPU fallback strategy (detection/recognition split deferred pending Marker API changes)
</success_criteria>

<output>
After completion, create `.planning/phases/12-device-configuration/12-05-SUMMARY.md`
</output>
