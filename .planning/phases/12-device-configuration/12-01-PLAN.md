---
phase: 12-device-configuration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/device.py
autonomous: true

must_haves:
  truths:
    - "DeviceType enum distinguishes cuda, mps, and cpu devices"
    - "DeviceInfo dataclass captures device metadata and fallback history"
    - "detect_device() returns validated device with CUDA > MPS > CPU priority"
    - "Validation allocates test tensor to confirm device actually works"
  artifacts:
    - path: "src/scholardoc_ocr/device.py"
      provides: "Device detection, validation, and fallback infrastructure"
      exports: ["DeviceType", "DeviceInfo", "detect_device"]
      min_lines: 80
  key_links:
    - from: "src/scholardoc_ocr/device.py"
      to: "torch.backends.mps"
      via: "MPS availability check"
      pattern: "torch\\.backends\\.mps\\.is_available"
    - from: "src/scholardoc_ocr/device.py"
      to: "torch.cuda"
      via: "CUDA availability check"
      pattern: "torch\\.cuda\\.is_available"
---

<objective>
Create device.py module with device detection and validation infrastructure.

Purpose: Establish foundation for GPU-accelerated OCR by detecting best available device
         (CUDA > MPS > CPU) with validation to ensure the device actually works.

Output: New device.py module with DeviceType enum, DeviceInfo dataclass, and detect_device() function.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-device-configuration/12-RESEARCH.md

Reference existing timing.py for pattern of lazy torch imports:
@src/scholardoc_ocr/timing.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create device.py with types and detection</name>
  <files>src/scholardoc_ocr/device.py</files>
  <action>
Create new device.py module with:

1. Module docstring explaining lazy torch imports

2. DeviceType enum (StrEnum):
   - CUDA = "cuda"
   - MPS = "mps"
   - CPU = "cpu"

3. DeviceInfo dataclass:
   - device_type: DeviceType
   - device_name: str (e.g., "NVIDIA A100", "Apple Silicon", "cpu")
   - validated: bool = False
   - fallback_from: DeviceType | None = None (tracks if we fell back)

4. detect_device() function:
   - Lazy import torch inside function (not at module level)
   - Priority order: CUDA > MPS > CPU
   - For CUDA: check is_available(), then validate with test tensor allocation
   - For MPS: check is_available() AND is_built(), then validate with test tensor
   - For CPU: always works, no validation needed
   - Log device selection at INFO level: "Using device: {device_type}"
   - On validation failure, log at WARNING and try next device
   - Returns DeviceInfo with validated=True and fallback_from set if applicable

5. Use TYPE_CHECKING pattern for torch type hints (avoid import at module level)

Key patterns from RESEARCH.md:
- torch.backends.mps.is_built() distinguishes "not built" from "not available"
- Test tensor allocation: torch.zeros(1, device=device_str)
- Get CUDA device name: torch.cuda.get_device_name(0)
  </action>
  <verify>
Run: python -c "from scholardoc_ocr.device import DeviceType, DeviceInfo, detect_device; d = detect_device(); print(f'{d.device_type}: {d.device_name}, validated={d.validated}')"

Expected: Prints device info without import errors. On Apple Silicon: "mps: Apple Silicon, validated=True"
  </verify>
  <done>
DeviceType enum, DeviceInfo dataclass, and detect_device() function exist and return validated device info
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for device detection</name>
  <files>tests/test_device.py</files>
  <action>
Create tests/test_device.py with:

1. Test DeviceType enum values are correct strings

2. Test DeviceInfo dataclass:
   - Default values (validated=False, fallback_from=None)
   - Custom values including fallback_from

3. Test detect_device() returns valid DeviceInfo:
   - Returns one of the valid DeviceTypes
   - validated is True
   - device_name is non-empty string

4. Test detect_device() is idempotent (multiple calls return same result)

5. Skip CUDA-specific tests on non-CUDA machines (pytest.mark.skipif)
6. Skip MPS-specific tests on non-macOS machines (pytest.mark.skipif)

Use fixtures:
- `@pytest.fixture` for device_info = detect_device()
  </action>
  <verify>
Run: pytest tests/test_device.py -v

Expected: All tests pass
  </verify>
  <done>
Unit tests for device module exist and pass
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/device.py` - no lint errors
2. `ruff format --check src/scholardoc_ocr/device.py` - properly formatted
3. `pytest tests/test_device.py -v` - all tests pass
4. `python -c "from scholardoc_ocr.device import detect_device; detect_device()"` - no import errors
</verification>

<success_criteria>
- device.py module exists with DeviceType, DeviceInfo, detect_device exports
- detect_device() returns validated device with correct priority order
- Lazy torch imports prevent loading ML dependencies at module import
- Unit tests verify device detection behavior
- DEV-01 foundation established (explicit device selection infrastructure)
- DEV-02 foundation established (device validation with test tensor)
</success_criteria>

<output>
After completion, create `.planning/phases/12-device-configuration/12-01-SUMMARY.md`
</output>
