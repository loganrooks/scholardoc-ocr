---
phase: 12-device-configuration
plan: 04
type: execute
wave: 2
depends_on: ["12-01", "12-02"]
files_modified:
  - src/scholardoc_ocr/cli.py
  - src/scholardoc_ocr/pipeline.py
  - src/scholardoc_ocr/environment.py
autonomous: true

must_haves:
  truths:
    - "CLI shows device info on startup when verbose"
    - "--strict-gpu flag exists and disables CPU fallback"
    - "environment.py validates MPS availability with actionable error messages"
    - "Startup validation shows 'MPS available' or explains why not"
  artifacts:
    - path: "src/scholardoc_ocr/cli.py"
      provides: "--strict-gpu CLI flag"
      contains: "strict-gpu"
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "strict_gpu config option"
      contains: "strict_gpu"
    - path: "src/scholardoc_ocr/environment.py"
      provides: "MPS validation diagnostics"
      contains: "mps"
  key_links:
    - from: "src/scholardoc_ocr/cli.py"
      to: "src/scholardoc_ocr/pipeline.py"
      via: "strict_gpu config propagation"
      pattern: "strict_gpu"
---

<objective>
Add CLI --strict-gpu flag, startup device validation, and actionable error messages.

Purpose: Give users control over fallback behavior and clear visibility into
         device availability at startup for debugging and performance tuning.

Output: --strict-gpu flag, improved startup diagnostics, MPS validation.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-device-configuration/12-RESEARCH.md
@.planning/phases/12-device-configuration/12-01-SUMMARY.md
@.planning/phases/12-device-configuration/12-02-SUMMARY.md

Reference current implementations:
@src/scholardoc_ocr/cli.py
@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/environment.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add MPS validation to environment.py</name>
  <files>src/scholardoc_ocr/environment.py</files>
  <action>
Modify environment.py:

1. Add new function to check GPU availability:
   ```python
   def check_gpu_availability() -> tuple[bool, str]:
       """Check GPU availability and return status message.

       Returns:
           Tuple of (available, message) where message explains the status.
       """
   ```

   Logic:
   - Try importing torch (lazy)
   - Check CUDA first: if torch.cuda.is_available(), return (True, "CUDA available: {device_name}")
   - Check MPS:
     a. If torch.backends.mps.is_available(): return (True, "MPS available (Apple Silicon)")
     b. If torch.backends.mps.is_built() but not is_available():
        return (False, "MPS built but not available (macOS < 12.3 or no GPU)")
     c. If not is_built(): return (False, "MPS not available (PyTorch not built with MPS)")
   - Return (False, "GPU not available, will use CPU")

2. Add GPU diagnostics to log_startup_diagnostics():
   ```python
   gpu_available, gpu_message = check_gpu_availability()
   logger.info("GPU: %s", gpu_message)
   ```

3. Do NOT make GPU a hard requirement in validate_environment():
   - GPU is optional; CPU fallback is always available
   - Just log the status for user awareness
  </action>
  <verify>
Run: python -c "from scholardoc_ocr.environment import check_gpu_availability; avail, msg = check_gpu_availability(); print(f'Available: {avail}, Message: {msg}')"

Expected: On Apple Silicon: "Available: True, Message: MPS available (Apple Silicon)"
  </verify>
  <done>
environment.py has check_gpu_availability() with actionable messages and startup diagnostics
  </done>
</task>

<task type="auto">
  <name>Task 2: Add --strict-gpu flag to CLI and PipelineConfig</name>
  <files>src/scholardoc_ocr/cli.py, src/scholardoc_ocr/pipeline.py</files>
  <action>
Modify cli.py:

1. Add argument after --force-surya:
   ```python
   parser.add_argument(
       "--strict-gpu",
       action="store_true",
       help="Fail if GPU (MPS/CUDA) unavailable instead of falling back to CPU.",
   )
   ```

2. Add to PipelineConfig construction:
   ```python
   strict_gpu=args.strict_gpu,
   ```

3. In verbose startup section (after log_startup_diagnostics), add:
   ```python
   from .environment import check_gpu_availability
   if args.verbose:
       gpu_available, gpu_message = check_gpu_availability()
       console.print(f"[dim]GPU: {gpu_message}[/dim]")
   ```

Modify pipeline.py:

1. Add field to PipelineConfig dataclass:
   ```python
   strict_gpu: bool = False
   ```

2. Pass strict_gpu when loading models (in Surya phase):
   - This will be used in a future plan when we integrate load_models_with_fallback
   - For now, just add the field to config
  </action>
  <verify>
Run: ocr --help | grep -A1 "strict-gpu"

Expected: Shows --strict-gpu flag with help text about failing if GPU unavailable
  </verify>
  <done>
--strict-gpu flag exists in CLI and strict_gpu field exists in PipelineConfig
  </done>
</task>

<task type="auto">
  <name>Task 3: Add integration test for device startup</name>
  <files>tests/test_device.py</files>
  <action>
Add to tests/test_device.py:

1. Test check_gpu_availability returns valid tuple:
   ```python
   def test_check_gpu_availability_returns_tuple():
       from scholardoc_ocr.environment import check_gpu_availability
       available, message = check_gpu_availability()
       assert isinstance(available, bool)
       assert isinstance(message, str)
       assert len(message) > 0
   ```

2. Test PipelineConfig has strict_gpu field:
   ```python
   def test_pipeline_config_has_strict_gpu():
       from scholardoc_ocr.pipeline import PipelineConfig
       config = PipelineConfig()
       assert hasattr(config, "strict_gpu")
       assert config.strict_gpu is False  # Default value
   ```

3. Test CLI parses --strict-gpu flag (mock argparse):
   ```python
   def test_cli_strict_gpu_flag():
       import sys
       from unittest.mock import patch
       # Test that --strict-gpu is recognized
       with patch.object(sys, "argv", ["ocr", "--strict-gpu", "."]):
           from scholardoc_ocr.cli import main
           # Just verify no parse error - don't run full pipeline
   ```
  </action>
  <verify>
Run: pytest tests/test_device.py -v -k "gpu_availability or strict_gpu"

Expected: All new tests pass
  </verify>
  <done>
Tests verify GPU availability check and strict_gpu flag integration
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/cli.py src/scholardoc_ocr/pipeline.py src/scholardoc_ocr/environment.py` - no lint errors
2. `ruff format --check src/scholardoc_ocr/cli.py src/scholardoc_ocr/pipeline.py src/scholardoc_ocr/environment.py` - properly formatted
3. `pytest tests/test_device.py -v` - all tests pass
4. `ocr --help | grep strict-gpu` - flag appears in help
5. `python -c "from scholardoc_ocr.environment import check_gpu_availability; print(check_gpu_availability())"` - returns tuple
</verification>

<success_criteria>
- --strict-gpu CLI flag exists and is documented in --help
- PipelineConfig.strict_gpu field exists with default False
- check_gpu_availability() returns actionable status message
- Verbose mode shows GPU availability at startup
- DEV-02 requirements met (startup validation with actionable messages)
</success_criteria>

<output>
After completion, create `.planning/phases/12-device-configuration/12-04-SUMMARY.md`
</output>
