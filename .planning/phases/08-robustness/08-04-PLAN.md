---
phase: 08-robustness
plan: 04
type: execute
wave: 2
depends_on: ["08-01", "08-02", "08-03"]
files_modified:
  - src/scholardoc_ocr/pipeline.py
  - src/scholardoc_ocr/cli.py
autonomous: true

must_haves:
  truths:
    - "Work directory is automatically removed after successful pipeline completion"
    - "--keep-intermediates flag preserves work directory for debugging"
    - "A slow PDF times out instead of hanging the entire pipeline"
    - "Pipeline uses QueueHandler logging from logging_.py for worker processes"
    - "CLI calls validate_environment() and log_startup_diagnostics() before pipeline dispatch"
    - "Per-worker log files are written to output_dir/logs/"
  artifacts:
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Integrated logging, cleanup, and timeout in run_pipeline"
      contains: "worker_log_initializer"
    - path: "src/scholardoc_ocr/cli.py"
      provides: "CLI --keep-intermediates, --timeout flags, env validation call"
      contains: "keep-intermediates"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/logging_.py"
      via: "import setup_main_logging, worker_log_initializer, stop_logging"
      pattern: "from .logging_ import"
    - from: "src/scholardoc_ocr/cli.py"
      to: "src/scholardoc_ocr/environment.py"
      via: "import validate_environment, log_startup_diagnostics"
      pattern: "from .environment import"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "concurrent.futures.Future.result"
      via: "timeout parameter"
      pattern: "result\\(timeout="
---

<objective>
Integrate the logging, environment, and error handling modules into the pipeline and CLI. Add work directory cleanup, --keep-intermediates flag, and per-file timeout protection.

Purpose: ROBU-04, ROBU-05, ROBU-06 — wire everything together so the pipeline operates reliably with observable diagnostics, cleans up after itself, and doesn't hang on bad files.
Output: Updated pipeline.py and cli.py with full robustness integration.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-robustness/08-RESEARCH.md
@.planning/phases/08-robustness/08-01-SUMMARY.md
@.planning/phases/08-robustness/08-02-SUMMARY.md
@.planning/phases/08-robustness/08-03-SUMMARY.md
@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/cli.py
@src/scholardoc_ocr/logging_.py
@src/scholardoc_ocr/environment.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate logging, timeout, and cleanup into pipeline.py</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Modify `pipeline.py`:

1. Add to `PipelineConfig`:
   - `keep_intermediates: bool = False`
   - `timeout: int = 1800`  (30 minutes default, per-file timeout in seconds)

2. In `run_pipeline()`:
   a. At the start, import and call `setup_main_logging`:
      ```python
      from .logging_ import setup_main_logging, worker_log_initializer, stop_logging
      log_dir = config.output_dir / "logs"
      log_dir.mkdir(parents=True, exist_ok=True)
      log_queue, log_listener = setup_main_logging(log_dir=log_dir, verbose=config.debug)
      ```
   b. Pass `initializer=worker_log_initializer, initargs=(log_queue, log_dir)` to `ProcessPoolExecutor`
   c. Wrap the entire pipeline body in `try/finally` that calls `stop_logging(log_listener)` in the finally block
   d. Change `future.result()` to `future.result(timeout=config.timeout)`. Catch `TimeoutError` separately:
      ```python
      except TimeoutError:
          logger.error("%s: timed out after %ds", path.name, config.timeout)
          file_results.append(FileResult(
              filename=path.name, success=False, engine=OCREngine.NONE,
              quality_score=0.0, page_count=0, pages=[],
              error=f"Timed out after {config.timeout}s",
          ))
      ```
   e. After ALL processing (after Phase 2 Surya), add work directory cleanup:
      ```python
      work_dir = config.output_dir / "work"
      if work_dir.exists() and not config.keep_intermediates:
          shutil.rmtree(work_dir, ignore_errors=True)
          logger.info("Cleaned up work directory")
      elif config.keep_intermediates:
          logger.info("Keeping work directory: %s", work_dir)
      ```
      Place this BEFORE the final `return BatchResult(...)`, inside the try block but after all processing.
  </action>
  <verify>
    `ruff check src/scholardoc_ocr/pipeline.py`
    `python -c "from scholardoc_ocr.pipeline import PipelineConfig; c = PipelineConfig(); assert c.timeout == 1800; assert c.keep_intermediates == False; print('OK')"`
  </verify>
  <done>pipeline.py uses QueueHandler logging for workers, has per-file timeout, and cleans up work directory after completion.</done>
</task>

<task type="auto">
  <name>Task 2: Add CLI flags and environment validation to cli.py</name>
  <files>src/scholardoc_ocr/cli.py</files>
  <action>
Modify `cli.py`:

1. Add CLI arguments:
   - `--keep-intermediates`: `action="store_true"`, help="Keep work directory for debugging"
   - `--timeout`: `type=int, default=1800`, help="Per-file timeout in seconds (default: 1800)"

2. After language resolution and before pipeline dispatch, add environment validation:
   ```python
   from .environment import validate_environment, log_startup_diagnostics, EnvironmentError
   try:
       validate_environment(langs_tesseract=langs_tesseract)
   except EnvironmentError as e:
       console.print(f"[red]Environment check failed:[/red]")
       for problem in e.problems:
           console.print(f"  [red]•[/red] {problem}")
       sys.exit(1)
   ```

3. After validation, if verbose: call `log_startup_diagnostics(langs_tesseract=langs_tesseract)`

4. Pass new config fields to PipelineConfig:
   ```python
   keep_intermediates=args.keep_intermediates,
   timeout=args.timeout,
   ```

5. Remove `logging.basicConfig(...)` from cli.py — logging is now managed by pipeline.py's setup_main_logging. BUT keep the verbose flag available. The simplest approach: keep `logging.basicConfig` for the CLI process itself (before pipeline runs), and let pipeline.py set up QueueHandler logging for workers. Actually, the cleanest approach is:
   - Keep `logging.basicConfig` in cli.py for pre-pipeline logging (environment validation, file discovery)
   - The pipeline's `setup_main_logging` will reconfigure for the parallel section
   - This is fine because setup_main_logging clears and reconfigures handlers
  </action>
  <verify>
    `python -m scholardoc_ocr.cli --help | grep -E "keep-intermediates|timeout"`
    `ruff check src/scholardoc_ocr/cli.py`
  </verify>
  <done>CLI exposes --keep-intermediates and --timeout flags, validates environment at startup with clear error messages, and logs startup diagnostics in verbose mode.</done>
</task>

<task type="auto">
  <name>Task 3: Add integration tests for pipeline robustness features</name>
  <files>tests/test_robustness.py</files>
  <action>
Create `tests/test_robustness.py` with integration tests:

1. `test_work_dir_cleaned_after_success` — create a PipelineConfig pointing at a temp dir with no PDFs, run pipeline, verify `output_dir/work` does not exist (or is empty). This tests the cleanup path.

2. `test_keep_intermediates_preserves_work_dir` — same setup but with `keep_intermediates=True`, verify work dir exists after pipeline run.

3. `test_timeout_config_default` — verify PipelineConfig().timeout == 1800.

4. `test_pipeline_config_has_new_fields` — verify keep_intermediates and timeout fields exist with correct defaults.

These are lightweight tests that don't require actual PDFs or tesseract. They verify the config and cleanup mechanics.
  </action>
  <verify>`pytest tests/test_robustness.py -v`</verify>
  <done>Integration tests pass, confirming cleanup, keep-intermediates, and timeout config work correctly.</done>
</task>

</tasks>

<verification>
- `ruff check src/scholardoc_ocr/pipeline.py src/scholardoc_ocr/cli.py` passes
- `pytest tests/test_robustness.py tests/test_logging.py tests/test_environment.py -v` — all pass
- `python -m scholardoc_ocr.cli --help` shows --keep-intermediates and --timeout
- `pytest` — all existing tests still pass
</verification>

<success_criteria>
- Pipeline uses QueueHandler/QueueListener for worker logging
- Environment validated before pipeline dispatch with clear errors
- Work directory cleaned up after successful run
- --keep-intermediates preserves work directory
- Per-file timeout prevents pipeline hangs
- Per-worker log files written to output_dir/logs/
- All new and existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/08-robustness/08-04-SUMMARY.md`
</output>
