---
phase: 02-quality-analysis-enhancement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/types.py
  - src/scholardoc_ocr/dictionary.py
  - src/scholardoc_ocr/data/wordlist.txt
  - src/scholardoc_ocr/quality.py
autonomous: true

must_haves:
  truths:
    - "Dictionary signal scores text by checking words against a bundled word list"
    - "German philosophical vocabulary is included in whitelists and word list"
    - "Unknown but structurally valid words are penalized less than garbled nonsense"
  artifacts:
    - path: "src/scholardoc_ocr/types.py"
      provides: "SignalResult dataclass shared by all signal modules"
      exports: ["SignalResult"]
    - path: "src/scholardoc_ocr/dictionary.py"
      provides: "DictionarySignal class with score() method returning 0-1"
      exports: ["DictionarySignal"]
    - path: "src/scholardoc_ocr/data/wordlist.txt"
      provides: "Bundled word list (~20K English + academic terms)"
    - path: "src/scholardoc_ocr/quality.py"
      provides: "Updated VALID_TERMS with German philosophical vocabulary"
      contains: "GERMAN_PHILOSOPHY_TERMS"
  key_links:
    - from: "src/scholardoc_ocr/dictionary.py"
      to: "src/scholardoc_ocr/data/wordlist.txt"
      via: "loads word list at init"
      pattern: "wordlist\\.txt"
---

<objective>
Create the dictionary validation signal and German language support.

Purpose: Provides a dictionary-based quality signal that distinguishes "unknown but structured" words from garbled nonsense, and extends language coverage to German academic texts.
Output: dictionary.py module, bundled wordlist.txt, German terms added to quality.py whitelist.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-quality-analysis-enhancement/02-RESEARCH.md
@src/scholardoc_ocr/quality.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dictionary signal module and bundled word list</name>
  <files>src/scholardoc_ocr/types.py, src/scholardoc_ocr/dictionary.py, src/scholardoc_ocr/data/wordlist.txt</files>
  <action>
Create `src/scholardoc_ocr/data/` directory (with `__init__.py` is NOT needed — it's a data dir).

Create `src/scholardoc_ocr/data/wordlist.txt` containing ~20K most common English words (one per line, lowercase). Generate from a frequency list. Include common academic/scholarly terms (thesis, methodology, epistemology, hermeneutic, phenomenology, ontological, etc.). Include common French academic words (autrement, totalité, altérité, phénoménologie, etc.). Include common German philosophical terms from the research doc (vernunft, verstand, anschauung, urteilskraft, transzendental, etc.). Include Latin academic terms (a priori, cogito, etc. as single words). Target ~20,000 words total.

Create `src/scholardoc_ocr/dictionary.py` with class `DictionarySignal`:

```python
class DictionarySignal:
    def __init__(self, custom_vocab_path: Path | None = None):
        # Load bundled wordlist.txt using importlib.resources or __file__
        # Merge with custom_vocab_path if provided (one word per line)
        self._words: frozenset[str]  # all known words, lowercase

    def score(self, text: str) -> SignalResult:
        # Split text into words, strip punctuation
        # For each word:
        #   - Skip short words (<3 chars)
        #   - Check if lowercase form in self._words -> known
        #   - If unknown, check structural validity:
        #     - Has vowels and consonants in reasonable ratio
        #     - Not random character soup (check entropy or pattern)
        #     - If structurally valid: "unknown_structured" (light penalty)
        #     - If garbled: "unknown_garbled" (heavy penalty)
        # Return SignalResult with:
        #   name="dictionary"
        #   score= weighted ratio (known=1.0, unknown_structured=0.5, unknown_garbled=0.0)
        #   passed= score >= floor
        #   details= {"known_count": N, "unknown_structured": N, "unknown_garbled": N, "total": N}
```

Import `SignalResult` from `src/scholardoc_ocr/types.py` (add it there as a new dataclass):
```python
# Add to types.py:
@dataclass
class SignalResult:
    name: str
    score: float  # 0-1
    passed: bool
    details: dict
```
Then in dictionary.py: `from scholardoc_ocr.types import SignalResult`

The structural validity check should:
- Check vowel ratio (words with <10% vowels are likely garbled, except for known abbreviations)
- Check for repeated character sequences (e.g., "aaaa", "xzxz")
- Check word length vs unique chars ratio (very long words with few unique chars are garbled)
  </action>
  <verify>
`python -c "from scholardoc_ocr.dictionary import DictionarySignal; d = DictionarySignal(); r = d.score('The quick brown fox'); print(r.score, r.details)"` runs without error and returns score near 1.0.
`python -c "from scholardoc_ocr.dictionary import DictionarySignal; d = DictionarySignal(); r = d.score('xkjhf bvnmq zzzttt'); print(r.score, r.details)"` returns low score.
  </verify>
  <done>DictionarySignal loads bundled word list, scores known text high and garbled text low, distinguishes unknown-structured from unknown-garbled.</done>
</task>

<task type="auto">
  <name>Task 2: Add German philosophical vocabulary to quality.py whitelist</name>
  <files>src/scholardoc_ocr/quality.py</files>
  <action>
Add a `GERMAN_PHILOSOPHY_TERMS` frozenset to `QualityAnalyzer` containing German philosophical vocabulary (from research doc):

Kant: vernunft, verstand, anschauung, urteilskraft, pflicht, kategorisch, imperativ, transzendental, apriorisch, erkenntnis, erscheinung, noumenon, ding
Hegel: geist, aufhebung, dialektik, synthese, entfremdung, selbstbewusstsein, absolut, vermittlung, wirklichkeit
Husserl: intentionalität, epoché, reduktion, lebenswelt, noesis, noema, konstitution, evidenz
Heidegger (extending existing): lichtung, gestell, ereignis, kehre, gelassenheit, grundstimmung, unverborgenheit, seinsgeschichte
Common philosophical German: wissenschaft, grundlegung, weltanschauung, vorstellung, bestimmung, begrifflichkeit, zusammenhang, beziehung

Merge into VALID_TERMS (union of existing + new German terms).

Also add German compound suffixes awareness: update the consonant_cluster pattern check to be more lenient when the word ends with common German suffixes (-keit, -heit, -ung, -schaft, -lich, -isch, -tum, -nis). Do this by adding a pre-check before the pattern loop: if word ends with a known German suffix, skip consonant_cluster check for that word.

Update the language constants comment to note German support.
  </action>
  <verify>
`python -c "from scholardoc_ocr.quality import QualityAnalyzer; q = QualityAnalyzer(); r = q.analyze('Die Grundlegung der Wissenschaft erfordert eine transzendentale Untersuchung der Vernunft'); print(r.score, r.garbled_count)"` returns high score with 0 or very low garbled count.
`python -c "from scholardoc_ocr.quality import QualityAnalyzer; q = QualityAnalyzer(); r = q.analyze('Wissenschaft Gemeinschaft Freundlichkeit Eigenschaft Grundsätzlichkeit'); print('garbled:', r.garbled_count)"` returns garbled_count=0 (German compound words with suffixes -schaft, -keit, -lich must not trigger consonant_cluster false positives).
  </verify>
  <done>German philosophical terms are in VALID_TERMS, German compound words no longer trigger false positive garbled detection.</done>
</task>

</tasks>

<verification>
- `python -c "from scholardoc_ocr.types import SignalResult"` imports succeed
- `python -c "from scholardoc_ocr.dictionary import DictionarySignal"` imports succeed
- `python -c "from scholardoc_ocr.quality import QualityAnalyzer; print(len(QualityAnalyzer.VALID_TERMS))"` shows increased count (was ~40, now ~70+)
- Dictionary scores English academic text above 0.8
- Dictionary scores garbled text below 0.3
- German text not falsely flagged by quality analyzer
</verification>

<success_criteria>
Dictionary signal module exists and scores text quality via word list lookup. German philosophical vocabulary integrated into quality analyzer whitelist. German compound words handled without false positives.
</success_criteria>

<output>
After completion, create `.planning/phases/02-quality-analysis-enhancement/02-01-SUMMARY.md`
</output>
