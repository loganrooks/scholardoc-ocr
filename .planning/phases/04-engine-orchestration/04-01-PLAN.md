---
phase: 04-engine-orchestration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/pipeline.py
autonomous: true

must_haves:
  truths:
    - "run_pipeline() returns BatchResult with FileResult per file and PageResult per page"
    - "Tesseract phase runs in parallel via ProcessPoolExecutor with resource-aware worker count"
    - "Surya phase processes each file individually with shared models (no cross-file combined PDF)"
    - "Surya results are written back to output .txt files (BUG-01 fixed)"
    - "Surya text is extracted from convert_pdf() markdown output, not re-read from original (BUG-02 fixed)"
    - "Per-file try/except ensures one Surya failure does not lose other files' results"
    - "PipelineConfig includes force_surya flag"
  artifacts:
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Pipeline orchestration with per-file Surya batching"
      contains: "def run_pipeline"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/surya.py"
      via: "surya.load_models() and surya.convert_pdf()"
      pattern: "surya\\.convert_pdf"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/tesseract.py"
      via: "tesseract.run_ocr()"
      pattern: "tesseract\\.run_ocr"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/types.py"
      via: "Returns BatchResult containing FileResult/PageResult"
      pattern: "BatchResult\\("
---

<objective>
Rewrite pipeline.py to fix both critical Surya bugs, switch to per-file Surya batching with shared models, use Phase 2-3 backend modules and types, and implement resource-aware parallelism.

Purpose: This is the core fix — Surya results are currently never written back to files and never correctly extracted. The cross-file combined PDF approach is fragile. This plan replaces the broken orchestration with clean per-file processing.

Output: Rewritten pipeline.py that returns BatchResult, uses tesseract.py/surya.py backends, and writes Surya-enhanced text to output files.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/types.py
@src/scholardoc_ocr/callbacks.py
@src/scholardoc_ocr/surya.py
@src/scholardoc_ocr/tesseract.py
@src/scholardoc_ocr/processor.py
@src/scholardoc_ocr/quality.py
@src/scholardoc_ocr/exceptions.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite pipeline.py with per-file Surya and writeback</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Rewrite pipeline.py completely. Keep `PipelineConfig` dataclass (add `force_surya: bool = False` field). Remove `ExtendedResult` — use `FileResult`, `PageResult`, `BatchResult` from types.py instead. Remove `_process_single()` function.

New `run_pipeline(config, callback) -> BatchResult`:

1. **File discovery**: Resolve input files from config.files + config.input_dir. Validate they exist.

2. **Resource-aware worker calculation**:
   ```python
   total_cores = os.cpu_count() or 4
   num_files = len(input_files)
   jobs_per_file = max(1, total_cores // max(1, num_files))
   pool_workers = max(1, min(config.max_workers, total_cores // jobs_per_file))
   ```

3. **Phase 1 — Parallel Tesseract**: Use `ProcessPoolExecutor(max_workers=pool_workers)`. Submit `_tesseract_worker(input_path, output_dir, config_dict)` for each file. The worker function:
   - Creates work_dir and final_dir paths
   - Calls `processor.extract_text_by_page()` to check existing text quality
   - Uses `QualityAnalyzer.analyze_pages()` to score pages
   - If no bad pages and not force_tesseract: copy file as-is, return FileResult with engine=EXISTING
   - Else: call `tesseract.run_ocr()` (from Phase 3 module), re-extract text, re-analyze quality
   - Write Tesseract text to `final/{stem}.txt`, copy PDF to `final/{stem}.pdf`
   - Build `FileResult` with `PageResult` per page (page_number 0-indexed, quality_score, engine=TESSERACT or EXISTING, flagged=True if below threshold, text=page_text)
   - Return FileResult. If pages are flagged, set `success=True` but pages will have `flagged=True`

   IMPORTANT: The worker must be a top-level function (not nested) and accept only picklable args. Pass config as a plain dict, not dataclass. The worker must NOT import surya (heavy ML imports in subprocess would be wasteful).

4. **Phase 2 — Sequential Surya**: In main process after all Tesseract futures complete:
   - Collect files with any flagged pages (or all files if force_surya)
   - If none, skip to return
   - Call `surya.load_models()` once, emit ModelEvent callbacks
   - For each flagged file (per-file try/except):
     - Get bad page indices (0-indexed) from file_result.flagged_pages
     - Call `surya.convert_pdf(input_path, models, page_range=bad_indices)`
     - This returns a single markdown string for all requested pages
     - **WRITEBACK (BUG-01 fix)**: Read existing .txt from `final/{stem}.txt`. Split into page texts by `\n\n` separator. Replace the bad page sections with the Surya markdown. Write back to the .txt file.
     - Update the PageResult entries: set engine=SURYA for enhanced pages
     - Emit progress callback
   - On SuryaError for a file: log warning, keep Tesseract output (partial success), continue to next file

5. **Return** `BatchResult(files=all_file_results, total_time_seconds=elapsed)`

Key details:
- Use `from . import surya, tesseract` for backend modules
- Use `from .processor import PDFProcessor` for extract_text_by_page, get_page_count
- Use `from .quality import QualityAnalyzer` for page analysis
- Use `from .callbacks import NullCallback, PhaseEvent, ProgressEvent, ModelEvent`
- Use `from .types import BatchResult, FileResult, PageResult, OCREngine, PageStatus`
- All page numbers are 0-indexed internally
- The `_tesseract_worker` function must use `TesseractConfig(jobs=jobs_per_file, langs=config_dict["langs_tesseract"])` when calling `tesseract.run_ocr()`
- Remove ALL references to `PDFProcessor.run_tesseract`, `PDFProcessor.run_surya_batch`, `PDFProcessor.combine_pages_from_multiple_pdfs` — these no longer exist after Phase 3
- Remove `ProcessingResult` import from processor (it's a legacy type)
- Keep logging via the `logging` module for library code (no print statements)
  </action>
  <verify>
Run `ruff check src/scholardoc_ocr/pipeline.py` — no errors.
Run `python -c "from scholardoc_ocr.pipeline import run_pipeline, PipelineConfig; print('OK')"` — imports successfully.
Verify `PipelineConfig` has `force_surya` field.
Verify `run_pipeline` return type annotation is `BatchResult`.
Verify no references to `ExtendedResult`, `_process_single`, `combine_pages_from_multiple_pdfs`, or `run_surya_batch`.
  </verify>
  <done>
pipeline.py rewritten with per-file Surya batching, writeback to .txt files, resource-aware parallelism, and returns BatchResult. Both BUG-01 and BUG-02 are fixed. ExtendedResult and cross-file combined PDF approach eliminated.
  </done>
</task>

</tasks>

<verification>
- `ruff check src/scholardoc_ocr/pipeline.py` passes
- `python -c "from scholardoc_ocr.pipeline import run_pipeline, PipelineConfig"` imports
- `grep -c "ExtendedResult" src/scholardoc_ocr/pipeline.py` returns 0
- `grep -c "combine_pages" src/scholardoc_ocr/pipeline.py` returns 0
- `grep -c "run_surya_batch" src/scholardoc_ocr/pipeline.py` returns 0
- `grep -c "surya.convert_pdf" src/scholardoc_ocr/pipeline.py` returns >= 1
- `grep -c "tesseract.run_ocr" src/scholardoc_ocr/pipeline.py` returns >= 1
- `grep -c "BatchResult" src/scholardoc_ocr/pipeline.py` returns >= 1
- `grep -c "force_surya" src/scholardoc_ocr/pipeline.py` returns >= 1
</verification>

<success_criteria>
Pipeline module fully rewritten using Phase 2-3 infrastructure. Per-file Surya batching replaces cross-file combined PDF. Surya results written back to output text files. Resource-aware worker calculation implemented. Returns BatchResult with full page-level detail.
</success_criteria>

<output>
After completion, create `.planning/phases/04-engine-orchestration/04-01-SUMMARY.md`
</output>
