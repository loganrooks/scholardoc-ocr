---
phase: 11-benchmarking-foundation-metrics-fixes
plan: 05
type: execute
wave: 3
depends_on: ["11-02"]
files_modified:
  - .github/workflows/benchmark.yml
autonomous: true

must_haves:
  truths:
    - "GitHub Actions workflow runs benchmarks on push/PR"
    - "Benchmark results stored for historical comparison"
    - "CI fails if performance regresses beyond threshold"
  artifacts:
    - path: ".github/workflows/benchmark.yml"
      provides: "CI workflow for benchmark regression detection"
      contains: "github-action-benchmark"
  key_links:
    - from: ".github/workflows/benchmark.yml"
      to: "tests/benchmarks/"
      via: "pytest --benchmark-only"
      pattern: "benchmark-only"
---

<objective>
Create GitHub Actions workflow for benchmark regression detection.

Purpose: BENCH-03 requires CI pipeline integration to detect performance regressions. github-action-benchmark consumes pytest-benchmark JSON output and fails builds that exceed thresholds.

Output: .github/workflows/benchmark.yml with benchmark CI workflow.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/11-benchmarking-foundation-metrics-fixes/11-RESEARCH.md
@.planning/phases/11-benchmarking-foundation-metrics-fixes/11-02-SUMMARY.md

@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create benchmark CI workflow</name>
  <files>.github/workflows/benchmark.yml</files>
  <action>
Create .github/workflows/benchmark.yml:

```yaml
name: Benchmark

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

jobs:
  benchmark:
    runs-on: macos-14  # Apple Silicon (M-series) runner
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          brew install tesseract tesseract-lang

      - name: Install package with dev dependencies
        run: |
          pip install -e ".[dev]"

      - name: Run benchmarks
        run: |
          # Run benchmarks, skip if Surya not available
          pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-group-by=func \
            -v || echo "Benchmarks skipped or completed"

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: always() && hashFiles('benchmark-results.json') != ''
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Store results in gh-pages branch for historical tracking
          auto-push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
          # Alert and fail if 50% regression (150% of baseline)
          alert-threshold: '150%'
          fail-on-alert: true
          comment-on-alert: true
          # Save results even on PR (for comparison)
          save-data-file: ${{ github.event_name == 'push' }}

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        if: always() && hashFiles('benchmark-results.json') != ''
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30
```

Key points:
- Uses macos-14 (Apple Silicon M-series runner) for MPS benchmarks
- Installs tesseract via brew (required dependency)
- Runs pytest with --benchmark-only and JSON output
- Uses github-action-benchmark for regression detection
- 150% threshold = fails if 50% slower than baseline
- auto-push only on main branch pushes (not PRs)
- Uploads artifact for manual inspection
  </action>
  <verify>
    ls -la .github/workflows/benchmark.yml
    cat .github/workflows/benchmark.yml | head -20
  </verify>
  <done>
    CI workflow created with benchmark regression detection
  </done>
</task>

<task type="auto">
  <name>Task 2: Create .github/workflows directory if needed</name>
  <files>.github/workflows/benchmark.yml</files>
  <action>
Before writing the workflow file, ensure the directory exists:

```bash
mkdir -p .github/workflows
```

This is handled by the Write tool creating parent directories, but explicitly noted for clarity.

Also verify the workflow is valid YAML by checking syntax:
- Proper indentation (2 spaces)
- Valid GitHub Actions syntax
- All required fields present
  </action>
  <verify>
    python -c "import yaml; yaml.safe_load(open('.github/workflows/benchmark.yml'))" || echo "YAML check (requires PyYAML)"
    ls -la .github/workflows/
  </verify>
  <done>
    Workflow directory exists and YAML is syntactically valid
  </done>
</task>

</tasks>

<verification>
- .github/workflows/benchmark.yml exists
- File contains github-action-benchmark configuration
- File contains pytest --benchmark-only command
- File uses macos-14 runner (Apple Silicon)
- alert-threshold set to 150%
- fail-on-alert: true configured
</verification>

<success_criteria>
- GitHub Actions workflow file created
- Workflow runs benchmarks on push/PR to main
- Workflow uses github-action-benchmark for regression detection
- Workflow fails build on 50%+ performance regression
- Benchmark results stored as artifacts
</success_criteria>

<output>
After completion, create `.planning/phases/11-benchmarking-foundation-metrics-fixes/11-05-SUMMARY.md`
</output>
