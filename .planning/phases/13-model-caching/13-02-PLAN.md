---
phase: 13-model-caching
plan: 02
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - src/scholardoc_ocr/pipeline.py
  - tests/test_pipeline.py
autonomous: true

must_haves:
  truths:
    - "Pipeline uses ModelCache.get_models() instead of surya.load_models() directly"
    - "GPU memory is cleaned up between documents during Surya phase"
    - "Model load time is still tracked in phase_timings"
  artifacts:
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Pipeline orchestration using cached models"
      contains: "ModelCache"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/model_cache.py"
      via: "import and get_instance().get_models()"
      pattern: "ModelCache\\.get_instance\\(\\)\\.get_models\\(\\)"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "cleanup_between_documents()"
      via: "call after each file in Surya phase"
      pattern: "cleanup_between_documents\\(\\)"
---

<objective>
Integrate ModelCache into the pipeline for model reuse and add inter-document memory cleanup.

Purpose: Connect the caching infrastructure to the actual OCR pipeline, delivering MODEL-01 (caching across requests) and MODEL-03 (memory cleanup between documents) for real workloads.

Output: Modified pipeline.py that uses cached models and performs GPU cleanup between files.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-model-caching/13-01-SUMMARY.md

@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/model_cache.py
@tests/test_pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update pipeline.py to use ModelCache</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Modify the `run_pipeline()` function in Phase 2 (Surya processing) to use ModelCache instead of direct surya.load_models():

1. **Add import at top of function body** (lazy, inside run_pipeline):
   ```python
   from .model_cache import ModelCache, cleanup_between_documents
   ```

2. **Replace model loading** (around line 380-388):

   BEFORE:
   ```python
   t0 = time.time()
   model_dict, device_used = surya.load_models()  # Now returns tuple
   mps_sync()  # Ensure GPU work completes before timing
   surya_model_load_time = time.time() - t0
   ```

   AFTER:
   ```python
   cache = ModelCache.get_instance()
   t0 = time.time()
   model_dict, device_used = cache.get_models()
   mps_sync()  # Ensure GPU work completes before timing
   surya_model_load_time = time.time() - t0
   # Note: surya_model_load_time will be ~0 on cache hit
   ```

3. **Add memory cleanup after each file** in the Surya processing loop (after line ~520, after the logger.info for Surya enhancement complete):
   ```python
   # Clean up GPU memory between documents (MODEL-03)
   cleanup_between_documents()
   ```

   Place this AFTER the successful completion of each file's Surya processing, before the except block.

4. **Keep existing surya import** - still needed for convert_pdf_with_fallback and SuryaConfig.

The cache.get_models() call will:
- Return cached models instantly on subsequent pipeline runs (MCP requests)
- Load fresh models on first call or after TTL expiration
- Still track load time in phase_timings (will be ~0 on cache hit, which is the desired behavior)
  </action>
  <verify>grep -q "ModelCache" src/scholardoc_ocr/pipeline.py && grep -q "cleanup_between_documents" src/scholardoc_ocr/pipeline.py</verify>
  <done>pipeline.py imports and uses ModelCache and cleanup_between_documents</done>
</task>

<task type="auto">
  <name>Task 2: Add pipeline integration tests for caching</name>
  <files>tests/test_pipeline.py</files>
  <action>
Add integration tests to verify caching behavior in the pipeline:

1. **Test model cache is used** (mock-based):
   ```python
   def test_pipeline_uses_model_cache(tmp_path, mocker):
       """Verify pipeline uses ModelCache instead of direct load_models."""
       # Create minimal test PDF
       # ...

       # Mock ModelCache
       mock_cache_instance = mocker.MagicMock()
       mock_cache_instance.get_models.return_value = ({}, "cpu")
       mock_get_instance = mocker.patch(
           "scholardoc_ocr.pipeline.ModelCache.get_instance",
           return_value=mock_cache_instance
       )

       # Also mock cleanup_between_documents
       mock_cleanup = mocker.patch(
           "scholardoc_ocr.pipeline.cleanup_between_documents"
       )

       # Run pipeline with force_surya to trigger Surya phase
       # ...

       # Verify ModelCache was used
       mock_get_instance.assert_called()
       mock_cache_instance.get_models.assert_called()
   ```

2. **Test cleanup called between files** (mock-based):
   ```python
   def test_pipeline_cleanup_between_documents(tmp_path, mocker):
       """Verify cleanup_between_documents called after each Surya file."""
       # Create two test PDFs
       # ...

       # Mock everything to avoid actual OCR
       mock_cache_instance = mocker.MagicMock()
       mock_cache_instance.get_models.return_value = ({}, "cpu")
       mocker.patch(
           "scholardoc_ocr.pipeline.ModelCache.get_instance",
           return_value=mock_cache_instance
       )
       mock_cleanup = mocker.patch(
           "scholardoc_ocr.pipeline.cleanup_between_documents"
       )

       # Mock surya.convert_pdf_with_fallback to return quickly
       mocker.patch(
           "scholardoc_ocr.surya.convert_pdf_with_fallback",
           return_value=("mock text", False)
       )

       # Run with force_surya
       # ...

       # Verify cleanup called for each file
       assert mock_cleanup.call_count >= 1  # At least once per file
   ```

Note: These tests use mocking to avoid actually loading ML models. The existing test fixtures create minimal PDFs.

Use pytest-mock's `mocker` fixture for mocking.
  </action>
  <verify>pytest tests/test_pipeline.py -v -k "cache" --tb=short</verify>
  <done>Pipeline caching tests pass</done>
</task>

</tasks>

<verification>
1. `grep -q "ModelCache" src/scholardoc_ocr/pipeline.py` - import present
2. `grep -q "cleanup_between_documents" src/scholardoc_ocr/pipeline.py` - cleanup called
3. `pytest tests/test_pipeline.py -v --tb=short` - all pipeline tests pass
4. `ruff check src/scholardoc_ocr/pipeline.py` - no lint errors
</verification>

<success_criteria>
- Pipeline imports and uses ModelCache.get_instance().get_models()
- cleanup_between_documents() called after each file in Surya phase
- Model load time still tracked in phase_timings (will be ~0 on cache hit)
- All existing pipeline tests continue to pass
- New caching integration tests pass
- No ruff lint errors
</success_criteria>

<output>
After completion, create `.planning/phases/13-model-caching/13-02-SUMMARY.md`
</output>
