---
phase: 14-cross-file-batching
plan: 03
type: execute
wave: 3
depends_on: ["14-02"]
files_modified:
  - src/scholardoc_ocr/batch.py
  - src/scholardoc_ocr/pipeline.py
  - tests/test_batch.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Memory pressure is monitored before batch processing"
    - "Batch sizes can be reduced if memory is constrained"
    - "Conservative defaults prevent system freezes on 8GB machines"
  artifacts:
    - path: "src/scholardoc_ocr/batch.py"
      provides: "Memory monitoring and adaptive sizing"
      exports: ["check_memory_pressure", "compute_safe_batch_size"]
      min_lines: 200
    - path: "tests/test_batch.py"
      provides: "Memory pressure and adaptive sizing tests"
      min_lines: 180
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/batch.py"
      via: "check_memory_pressure before Surya call"
      pattern: "check_memory_pressure"
---

<objective>
Add adaptive batch sizing based on memory pressure monitoring.

Purpose: BATCH-05 requires batch size adaptation based on actual memory pressure. Large batches on memory-constrained systems (8GB MPS) can cause system freezes without Python OOM errors. This plan adds pre-batch memory checking and conservative batch size computation to prevent issues.

Output: Memory pressure monitoring functions, conservative batch sizing logic, and comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-cross-file-batching/14-RESEARCH.md
@.planning/phases/14-cross-file-batching/14-01-SUMMARY.md
@.planning/phases/14-cross-file-batching/14-02-SUMMARY.md
@src/scholardoc_ocr/batch.py
@src/scholardoc_ocr/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add memory pressure monitoring to batch.py</name>
  <files>src/scholardoc_ocr/batch.py</files>
  <action>
Add memory monitoring functions to src/scholardoc_ocr/batch.py:

1. **check_memory_pressure() -> tuple[bool, float]**:
   - Returns (is_constrained, available_gb)
   - Uses psutil.virtual_memory().available for system available memory
   - is_constrained = True if available < 4GB (conservative threshold for MPS)
   - Example:
     ```python
     def check_memory_pressure() -> tuple[bool, float]:
         """Check if system is under memory pressure.

         Returns:
             Tuple of (is_constrained, available_gb).
             is_constrained is True if available memory < 4GB.
         """
         mem = psutil.virtual_memory()
         available_gb = mem.available / (1024**3)
         is_constrained = available_gb < 4.0
         return is_constrained, available_gb
     ```

2. **compute_safe_batch_size(total_pages: int, available_memory_gb: float, device: str) -> int**:
   - Compute batch size based on available memory and page count
   - Memory per page estimate: ~700MB at peak (detection + recognition + layout)
   - Use 50% of available memory for safety margin
   - Clamp to reasonable range (1 to min(total_pages, 100))
   - Example:
     ```python
     def compute_safe_batch_size(
         total_pages: int,
         available_memory_gb: float,
         device: str,
     ) -> int:
         """Compute safe batch size based on available memory.

         Args:
             total_pages: Number of pages to process.
             available_memory_gb: Available system memory in GB.
             device: Device type ("mps", "cuda", "cpu").

         Returns:
             Recommended batch size (clamped to 1-100 range).
         """
         if device == "cpu":
             # CPU is more memory-efficient but slower
             return min(total_pages, 32)

         # GPU: use 50% of available for safety
         memory_per_page_gb = 0.7  # Conservative estimate
         safe_memory = available_memory_gb * 0.5
         max_by_memory = int(safe_memory / memory_per_page_gb)

         return max(1, min(total_pages, max_by_memory, 100))
     ```

3. **Add BATCH_SIZE_MEMORY_PER_PAGE constant**:
   - Document the 700MB estimate source (from research)
   - Make it easy to tune if needed
  </action>
  <verify>
    - `python -c "from scholardoc_ocr.batch import check_memory_pressure, compute_safe_batch_size; print('imports ok')"` succeeds
    - `ruff check src/scholardoc_ocr/batch.py` passes
  </verify>
  <done>
    - check_memory_pressure returns (is_constrained, available_gb)
    - compute_safe_batch_size returns conservative batch size
    - Memory thresholds documented
    - No new dependencies added
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate memory checks into pipeline</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Update src/scholardoc_ocr/pipeline.py to use memory monitoring:

1. **Before Surya batch processing, check memory**:
   After configuring batch sizes, before creating combined PDF:
   ```python
   from .batch import check_memory_pressure, compute_safe_batch_size

   # Check memory pressure before batch (BATCH-05)
   is_constrained, available_mem = check_memory_pressure()
   if is_constrained:
       safe_size = compute_safe_batch_size(len(flagged_pages), available_mem, device_used)
       logger.warning(
           "Memory constrained (%.1fGB available). Recommended batch size: %d pages",
           available_mem,
           safe_size,
       )
   ```

2. **Log batch size configuration**:
   Update the existing batch config logging to include:
   - Total flagged pages
   - Whether memory is constrained
   - Effective batch size (from env vars)

3. **Add phase_timings entry for batch info**:
   For each file_result that used Surya:
   ```python
   file_result.phase_timings["surya_batch_pages"] = len(flagged_pages)
   file_result.phase_timings["surya_batch_files"] = len(flagged_results)
   ```

This provides visibility into batch processing without changing the core batch sizes (which are set via env vars read at import time).
  </action>
  <verify>
    - `ruff check src/scholardoc_ocr/pipeline.py` passes
    - `pytest tests/test_pipeline.py -v` passes
  </verify>
  <done>
    - Pipeline logs memory pressure warnings
    - Batch info stored in phase_timings
    - Existing tests still pass
    - Memory monitoring integrated non-intrusively
  </done>
</task>

<task type="auto">
  <name>Task 3: Add comprehensive tests for memory monitoring</name>
  <files>tests/test_batch.py</files>
  <action>
Add to tests/test_batch.py:

1. **TestCheckMemoryPressure class**:
   - test_returns_tuple: Returns (bool, float)
   - test_not_constrained_with_plenty_of_memory: >4GB available -> is_constrained=False
   - test_constrained_with_low_memory: <4GB available -> is_constrained=True
   - test_threshold_is_4gb: Exactly 4GB -> is_constrained=False, just under -> True
   - Use pytest.mark.parametrize for threshold testing
   - Mock psutil.virtual_memory to control available memory

2. **TestComputeSafeBatchSize class**:
   - test_cpu_max_32: CPU device always returns <= 32
   - test_gpu_scales_with_memory: More memory -> larger batch size
   - test_never_exceeds_total_pages: Batch size <= total_pages
   - test_never_exceeds_100: Batch size <= 100 (hard cap)
   - test_minimum_is_1: Always returns >= 1
   - test_8gb_mps_conservative: 8GB MPS gets batch ~5-6 (8*0.5/0.7)
   - test_32gb_mps_larger: 32GB MPS gets batch ~22 (32*0.5/0.7)

3. **TestIntegration class** (if not already exists):
   - test_full_batch_workflow: collect -> create_combined -> process -> map_results
   - Use small test PDFs created with fitz
   - Mock Surya conversion to return test markdown
  </action>
  <verify>
    - `pytest tests/test_batch.py -v` passes all tests
    - `ruff check tests/test_batch.py` passes
  </verify>
  <done>
    - Memory pressure tests cover threshold behavior
    - Batch size computation tests cover all device types
    - Integration tests verify full workflow
    - All tests pass
  </done>
</task>

</tasks>

<verification>
1. `ruff check src/scholardoc_ocr/batch.py src/scholardoc_ocr/pipeline.py tests/test_batch.py` - no lint errors
2. `pytest tests/test_batch.py tests/test_pipeline.py -v` - all tests pass
3. Manual verification: Run pipeline on constrained system, verify warning logged
</verification>

<success_criteria>
- Memory pressure monitoring works (check_memory_pressure returns accurate values)
- Batch size computation scales with available memory
- Pipeline logs memory warnings when constrained
- Batch info recorded in phase_timings for observability
- All tests pass including new memory monitoring tests
- System doesn't freeze on 8GB machines (conservative defaults)
</success_criteria>

<output>
After completion, create `.planning/phases/14-cross-file-batching/14-03-SUMMARY.md`
</output>
