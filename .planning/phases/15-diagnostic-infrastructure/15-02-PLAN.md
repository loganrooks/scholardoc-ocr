---
phase: 15-diagnostic-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - src/scholardoc_ocr/postprocess.py
  - src/scholardoc_ocr/pipeline.py
autonomous: true

must_haves:
  truths:
    - "Every PageResult from _tesseract_worker carries a PageDiagnostics with signal_scores, signal_details, composite_weights, signal_disagreements, has_signal_disagreement, and struggle_categories populated"
    - "Post-processing counters (dehyphenations, paragraph_joins, unicode_normalizations, punctuation_fixes) are tracked and attached to diagnostics"
    - "Pipeline output includes diagnostics data in the JSON metadata sidecar"
    - "Existing pipeline behavior is unchanged when diagnostics field is present (just carries extra data)"
  artifacts:
    - path: "src/scholardoc_ocr/postprocess.py"
      provides: "Postprocess functions with optional counter tracking"
      contains: "counts"
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Pipeline wiring of always-captured diagnostics through _tesseract_worker"
      contains: "build_always_diagnostics"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/diagnostics.py"
      via: "import and call build_always_diagnostics in _tesseract_worker"
      pattern: "build_always_diagnostics"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/postprocess.py"
      via: "pass counts dict to postprocess function"
      pattern: "counts="
---

<objective>
Wire always-captured diagnostic data through the pipeline: attach signal breakdowns and struggle categories to every PageResult from _tesseract_worker, and add postprocess change counters.

Purpose: DIAG-02, DIAG-03, DIAG-05, DIAG-06, DIAG-07 -- the "free" diagnostics that capture data already computed but currently discarded. After this plan, every page carries rich diagnostic metadata at near-zero marginal cost.

Output: Modified postprocess.py with counter tracking, modified pipeline.py with diagnostic wiring.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary-standard.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/15-diagnostic-infrastructure/15-CONTEXT.md
@.planning/phases/15-diagnostic-infrastructure/15-RESEARCH.md
@.planning/phases/15-diagnostic-infrastructure/15-01-SUMMARY.md
@src/scholardoc_ocr/postprocess.py
@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/diagnostics.py
@src/scholardoc_ocr/types.py
@src/scholardoc_ocr/quality.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add counter tracking to postprocess functions</name>
  <files>src/scholardoc_ocr/postprocess.py</files>
  <action>
Modify each postprocess transform function to accept an optional `counts: dict | None = None` parameter and increment counters when provided. The key constraint: existing callers that do NOT pass `counts` must get identical behavior (same signature, same return type).

1. `normalize_unicode(text, counts=None)` -- Count ligature replacements and soft hyphen removals. Increment `counts["unicode_normalizations"]` by total replacements made.

2. `dehyphenate(text, terms=None, counts=None)` -- Count successful dehyphenations (where hyphen-newline was rejoined). Increment `counts["dehyphenations"]` by count. The `_replace_hyphen` inner function needs access to a mutable counter. Use a list `[0]` or nonlocal variable inside the closure.

3. `join_paragraphs(text, counts=None)` -- Count lines that were joined (spaces added where newlines were). Increment `counts["paragraph_joins"]` by count.

4. `normalize_punctuation(text, counts=None)` -- Count substitutions made by each regex. Increment `counts["punctuation_fixes"]` by total substitutions. Use `re.subn()` instead of `re.sub()` to get replacement counts, or count before/after.

5. `postprocess(text, counts=None)` -- Pass `counts` dict through to each sub-function in the chain. This is the main entry point.

**Important:** Do NOT change return types. Each function still returns `str`. The `counts` dict is mutated in place as a side effect. When `counts is None`, no counting happens and the code path is identical to before.

**Counting approach:** For each function, use the simplest reliable counting method:
- For `re.sub` calls, switch to `re.subn` which returns `(result, count)` -- only when counts dict is provided (to avoid overhead otherwise)
- For loop-based transforms (dehyphenate, join_paragraphs), increment a local counter inside the loop

Initialize each key in counts only if it doesn't exist yet (use `counts.setdefault(key, 0)` or just `+= 1` after initializing with 0).
  </action>
  <verify>
Run `python -c "
from scholardoc_ocr.postprocess import postprocess
# Without counts -- identical behavior
result = postprocess('test-\ning text')
print(f'Without counts: {repr(result[:30])}')

# With counts -- same result plus counters
counts = {}
result2 = postprocess('test-\ning text with fi ligature and  extra  spaces', counts=counts)
print(f'With counts: {counts}')
assert isinstance(result2, str)
print('OK')
"`.

Run `pytest tests/ -x -q --timeout=30` to verify no regressions.

Run `ruff check src/scholardoc_ocr/postprocess.py`.
  </verify>
  <done>All 4 postprocess functions accept optional counts parameter. postprocess() passes counts through the chain. Existing callers unaffected. Counter dict populated with dehyphenations, paragraph_joins, unicode_normalizations, punctuation_fixes.</done>
</task>

<task type="auto">
  <name>Task 2: Wire always-captured diagnostics through _tesseract_worker and run_pipeline</name>
  <files>src/scholardoc_ocr/pipeline.py</files>
  <action>
Modify `pipeline.py` to attach PageDiagnostics to every PageResult created in `_tesseract_worker` and to carry postprocess counts.

**In `_tesseract_worker`:**

1. Add import at top of function (lazy, inside function body to match existing pattern):
   ```python
   from .diagnostics import build_always_diagnostics
   ```

2. **Existing-text-is-good path (line ~100-127):** After `page_results = analyzer.analyze_pages(page_texts)`, build diagnostics for each page. The `page_results` list already contains full QualityResult objects with signal_scores and signal_details. Create diagnostics and attach:
   ```python
   for i in range(page_count):
       qr = page_results[i] if i < len(page_results) else None
       diag = build_always_diagnostics(qr, threshold) if qr else None
       # attach to PageResult constructor below
   ```
   Also add postprocess counts: call `postprocess(text, counts=counts)` where `counts = {}`, then set `diag.postprocess_counts = counts` for the relevant pages. Note: in this path, the full text is postprocessed as one blob, so counts apply globally -- attach them to each page's diagnostics (this is approximate but acceptable; Phase 19 will refine).

3. **Tesseract-processed path (line ~152-194):** Same pattern. After `tess_page_results = analyzer.analyze_pages(tess_page_texts)`, build diagnostics for each page from the QualityResult. Then postprocess with counts and attach.

4. **Both paths:** When constructing PageResult objects, pass `diagnostics=diag` to the constructor.

**In `run_pipeline`:**

5. **Surya phase:** After `map_results_to_files()` is called (which may update page text and scores), the diagnostics from Phase 1 are already attached. For Surya-processed pages, update the struggle categories to potentially include `surya_insufficient` by calling `classify_struggle` again with the updated score and engine info. This is a lightweight re-classification. Import `classify_struggle` from diagnostics.

6. **Surya phase -- update diagnostics after Surya re-scoring:** After `map_results_to_files()` loop completes, iterate over flagged_results and their pages. For pages where `page.engine == OCREngine.SURYA` and `page.diagnostics is not None`:
   - Re-run `classify_struggle` with the updated quality_score, engine="surya", and surya_score=page.quality_score
   - Update `page.diagnostics.struggle_categories` with the new categories

**Do NOT change:**
- The overall pipeline flow or return types
- The ProcessPoolExecutor setup
- The Phase 2 (Surya) processing logic beyond the diagnostics update
- Any error handling paths (if diagnostics fail, log warning and continue with None)

**Error resilience:** Wrap diagnostic construction in try/except. If build_always_diagnostics fails for a page, set diagnostics=None and log a warning. Diagnostics must never break the pipeline.
  </action>
  <verify>
Run `pytest tests/ -x -q --timeout=30` to verify no regressions.

Run `python -c "
from scholardoc_ocr.pipeline import _tesseract_worker
from pathlib import Path
# Verify the import structure works (doesn't actually need a PDF)
print('Import OK')
"`.

Run `ruff check src/scholardoc_ocr/pipeline.py`.

For a more thorough check (if test PDFs exist): Run existing pipeline integration tests which exercise _tesseract_worker -- they should pass with diagnostics now attached.
  </verify>
  <done>Every PageResult from _tesseract_worker has a PageDiagnostics attached with signal_scores, signal_details, composite_weights, signal_disagreements, has_signal_disagreement, struggle_categories, and postprocess_counts populated. Surya-processed pages get updated struggle categories including surya_insufficient detection. Existing tests pass.</done>
</task>

</tasks>

<verification>
- `pytest tests/ -x -q --timeout=30` passes (no regressions)
- `ruff check src/scholardoc_ocr/postprocess.py src/scholardoc_ocr/pipeline.py` passes
- Postprocess functions accept counts parameter without breaking existing callers
- _tesseract_worker produces PageResult objects with diagnostics attached
- Diagnostics data survives ProcessPoolExecutor pickling (verified by pipeline tests passing)
</verification>

<success_criteria>
- DIAG-02: Signal breakdown (garbled, dictionary, confidence scores + weights) present in every PageResult diagnostics
- DIAG-03: Signal disagreements computed and stored with magnitudes; has_signal_disagreement flag set at 0.3 threshold
- DIAG-05: Post-processing counts (dehyphenations, paragraph_joins, unicode_normalizations, punctuation_fixes) tracked and attached
- DIAG-06: Struggle categories array populated for every page
- DIAG-07: PageResult.diagnostics field populated (always-captured tier)
- All existing tests pass unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/15-diagnostic-infrastructure/15-02-SUMMARY.md`
</output>
