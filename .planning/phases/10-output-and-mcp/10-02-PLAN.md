---
phase: 10-output-and-mcp
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/mcp_server.py
autonomous: true

must_haves:
  truths:
    - "MCP ocr_async() returns a job_id immediately without blocking"
    - "MCP ocr_status(job_id) returns current status, progress, and result when done"
    - "MCP ocr() reports coarse progress at phase boundaries via ctx logging"
    - "Completed jobs are cleaned up after TTL to prevent memory leaks"
  artifacts:
    - path: "src/scholardoc_ocr/mcp_server.py"
      provides: "ocr_async tool, ocr_status tool, JobState dataclass, job store with TTL cleanup"
      contains: "ocr_async"
  key_links:
    - from: "ocr_async"
      to: "asyncio.create_task"
      via: "spawns background task wrapping run_pipeline"
    - from: "ocr_status"
      to: "_jobs dict"
      via: "looks up JobState by job_id"
    - from: "ocr tool"
      to: "ctx.info"
      via: "reports phase-level progress during synchronous execution"
---

<objective>
Add async MCP job handling (OUTP-03) and progress reporting (OUTP-04) to the MCP server. `ocr_async()` returns a job ID immediately; `ocr_status()` retrieves progress and results. The existing synchronous `ocr()` tool gets coarse-grained progress via MCP Context logging.

Purpose: Long-running OCR jobs (10+ minutes) need async handling so Claude Desktop doesn't time out waiting for results.
Output: Updated mcp_server.py with ocr_async, ocr_status tools and progress reporting on ocr.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-output-and-mcp/10-RESEARCH.md
@src/scholardoc_ocr/mcp_server.py
@src/scholardoc_ocr/callbacks.py
@src/scholardoc_ocr/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Async job store and ocr_async/ocr_status tools</name>
  <files>src/scholardoc_ocr/mcp_server.py</files>
  <action>
1. Add imports at top: `import uuid`, `import time`, `from dataclasses import dataclass, field`.

2. Add `JobState` dataclass:
   ```python
   @dataclass
   class JobState:
       job_id: str
       status: str = "running"  # running | completed | failed
       progress: dict = field(default_factory=dict)
       result: dict | None = None
       error: str | None = None
       created_at: float = field(default_factory=time.time)
   ```

3. Add module-level job store and TTL constant:
   ```python
   _jobs: dict[str, JobState] = {}
   _JOB_TTL_SECONDS = 3600  # 1 hour
   ```

4. Add `_cleanup_expired_jobs()` helper that removes completed/failed jobs older than TTL. Call it lazily at the start of `ocr_async()` and `ocr_status()`.

5. Add `_run_job(job: JobState, config: PipelineConfig)` async helper:
   - Wraps `asyncio.to_thread(run_pipeline, config)` in try/except
   - On success: sets `job.status = "completed"`, `job.result = batch.to_dict()`
   - On failure: sets `job.status = "failed"`, `job.error = str(e)`
   - Uses a simple callback class that updates `job.progress` dict with phase/current/total info

6. Add `@mcp.tool() async def ocr_async(...)` with same params as existing `ocr()` tool:
   - Builds PipelineConfig same way as `ocr()`
   - Creates JobState with uuid4 job_id
   - Stores in `_jobs`
   - Spawns `asyncio.create_task(_run_job(job, config))`
   - Returns `{"job_id": job.job_id, "status": "running"}` immediately
   - Docstring: explains this is for long-running jobs, use ocr_status to check progress

7. Add `@mcp.tool() async def ocr_status(job_id: str) -> dict`:
   - Calls `_cleanup_expired_jobs()`
   - Looks up job in `_jobs`
   - If not found: `{"error": f"Unknown job: {job_id}"}`
   - Returns `{"job_id": ..., "status": ..., "progress": ..., "result": ..., "error": ...}`
  </action>
  <verify>
Run `ruff check src/scholardoc_ocr/mcp_server.py` — no errors.
Run `python -c "from scholardoc_ocr.mcp_server import mcp; print('import ok')"` — no import errors.
Run `pytest tests/ -x -q` — no regressions.
  </verify>
  <done>ocr_async returns job_id immediately. ocr_status retrieves job state. Jobs are cleaned up after 1 hour TTL.</done>
</task>

<task type="auto">
  <name>Task 2: Add progress reporting to synchronous ocr() tool</name>
  <files>src/scholardoc_ocr/mcp_server.py</files>
  <action>
1. Update the existing `ocr()` tool signature to accept MCP Context:
   ```python
   from mcp.server.fastmcp import Context
   from mcp.server.session import ServerSession

   @mcp.tool()
   async def ocr(input_path: str, ctx: Context, ...) -> dict:
   ```

2. Add `await ctx.info(...)` calls at key points:
   - Before pipeline run: `await ctx.info(f"Starting OCR: {resolved}")`
   - After pipeline run: `await ctx.info(f"OCR complete: {batch.success_count} succeeded, {batch.error_count} failed")`

3. For mid-pipeline progress: Since `run_pipeline` runs in a thread via `asyncio.to_thread()`, we CANNOT easily bridge async progress mid-execution. Accept coarse-grained progress (before/after) for the synchronous tool. Fine-grained progress is available via `ocr_async` + `ocr_status`. Add a comment explaining this limitation.

4. Also fix the existing extract_text handling in `ocr()`: Currently it re-extracts text from the output PDF via PyMuPDF, losing post-processing transforms. Instead, when extract_text=True, read the .txt file already written by the pipeline (set `config.extract_text = True` so pipeline preserves it). Return the .txt path in the response dict. If the .txt file exists, include `"text_path": str(txt_path)` in the response. Do NOT include the text content in the MCP response (it can be huge).
  </action>
  <verify>
Run `ruff check src/scholardoc_ocr/mcp_server.py` — no errors.
Run `python -c "from scholardoc_ocr.mcp_server import mcp; print('import ok')"` — no import errors.
Run `pytest tests/ -x -q` — no regressions.
  </verify>
  <done>Synchronous ocr() tool reports progress via ctx.info at phase boundaries. extract_text uses pipeline's post-processed .txt instead of re-extracting.</done>
</task>

</tasks>

<verification>
1. `ruff check src/` passes
2. `pytest tests/ -x -q` passes
3. `grep -c "ocr_async\|ocr_status\|JobState" src/scholardoc_ocr/mcp_server.py` returns >= 3
4. `grep -c "ctx.info\|Context" src/scholardoc_ocr/mcp_server.py` returns >= 2
</verification>

<success_criteria>
- ocr_async() tool registered, returns job_id without blocking
- ocr_status() tool retrieves job progress and results
- Synchronous ocr() reports progress via MCP Context
- Job TTL cleanup prevents memory leaks
- extract_text uses pipeline .txt output (not re-extraction)
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/10-output-and-mcp/10-02-SUMMARY.md`
</output>
