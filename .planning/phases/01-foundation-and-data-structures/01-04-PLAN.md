---
phase: 01-foundation-and-data-structures
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/scholardoc_ocr/pipeline.py
  - src/scholardoc_ocr/processor.py
  - tests/test_callbacks.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "run_pipeline() accepts a PipelineCallback parameter"
    - "PhaseEvent emitted exactly 4 times: started+completed for Tesseract, started+completed for Surya"
    - "ProgressEvent emitted once per file completed in Phase 1 (count == number of input files)"
    - "ModelEvent emitted from inside processor.py run_surya_batch around create_model_dict() call (not at PDFProcessor instantiation)"
    - "Default behavior uses LoggingCallback when no callback provided"
    - "processor.py run_surya_batch uses PipelineCallback instead of raw Callable"
  artifacts:
    - path: "src/scholardoc_ocr/pipeline.py"
      provides: "Callback-wired pipeline"
      contains: "PipelineCallback"
    - path: "src/scholardoc_ocr/processor.py"
      provides: "Protocol-based progress reporting in run_surya_batch"
      contains: "PipelineCallback"
    - path: "tests/test_callbacks.py"
      provides: "Integration test proving callbacks fire"
  key_links:
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "src/scholardoc_ocr/callbacks.py"
      via: "import and instantiation"
      pattern: "from .callbacks import"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "PipelineCallback.on_phase"
      via: "callback.on_phase(PhaseEvent(...))"
      pattern: "callback\\.on_phase"
    - from: "src/scholardoc_ocr/pipeline.py"
      to: "PipelineCallback.on_progress"
      via: "callback.on_progress(ProgressEvent(...))"
      pattern: "callback\\.on_progress"
---

<objective>
Wire the PipelineCallback protocol into pipeline.py and processor.py so that programmatic callers receive structured progress events.

Purpose: Close the critical gap from Phase 1 verification — callbacks.py exists but is completely orphaned. The phase goal "Progress reporting works via callback protocol (decoupled from Rich)" requires actual event emission.

Output: pipeline.py emits PhaseEvent, ProgressEvent, and ModelEvent at appropriate points; processor.py uses PipelineCallback instead of raw Callable; test proves events fire.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/scholardoc_ocr/callbacks.py
@src/scholardoc_ocr/pipeline.py
@src/scholardoc_ocr/processor.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire callbacks into pipeline.py and processor.py</name>
  <files>src/scholardoc_ocr/pipeline.py, src/scholardoc_ocr/processor.py</files>
  <action>
In pipeline.py:

1. Add import at top:
   `from .callbacks import PipelineCallback, LoggingCallback, NullCallback, ProgressEvent, PhaseEvent, ModelEvent`

2. Add `callback: PipelineCallback | None = None` parameter to `run_pipeline()` signature. As first line of function body, default to LoggingCallback:
   `cb: PipelineCallback = callback or LoggingCallback()`

3. Emit PhaseEvent at Phase 1 start (before ProcessPoolExecutor block, ~line 318):
   `cb.on_phase(PhaseEvent(phase="tesseract", status="started", files_count=len(input_files), pages_count=total_pages))`

4. Emit ProgressEvent inside the `for future in as_completed(...)` loop, after `results.append(result)` (~line 328). Track completed count with a counter variable:
   `cb.on_progress(ProgressEvent(phase="tesseract", current=completed, total=len(input_files), filename=result.filename))`

5. Emit PhaseEvent at Phase 1 end (after phase1_elapsed log, ~line 342):
   `cb.on_phase(PhaseEvent(phase="tesseract", status="completed", files_count=len(input_files), pages_count=total_pages))`

6. In Phase 2 (Surya) block, emit PhaseEvent started (~line 366):
   `cb.on_phase(PhaseEvent(phase="surya", status="started", files_count=len(needs_surya), pages_count=total_bad_pages))`

7. Do NOT emit ModelEvent at PDFProcessor() instantiation — models aren't loaded there. Instead, pass the callback to `run_surya_batch`:
   `surya_texts = surya_processor.run_surya_batch(combined_pdf, work_dir, batch_size=50, callback=cb)`

9. Emit PhaseEvent at Phase 2 end (after surya_elapsed log):
   `cb.on_phase(PhaseEvent(phase="surya", status="completed", files_count=len(needs_surya), pages_count=total_bad_pages))`

In processor.py:

1. Add import: `from .callbacks import PipelineCallback, ProgressEvent`

2. Change `run_surya_batch` signature: replace `progress_callback: Callable[[str, int, int], None] | None = None` with `callback: PipelineCallback | None = None`. Also import `ModelEvent`.

3. Emit ModelEvent around the `create_model_dict()` call inside `run_surya_batch` (this is where models actually load):
   ```python
   if callback:
       callback.on_model(ModelEvent(model_name="surya", status="loading"))
   model_dict = create_model_dict()
   if callback:
       callback.on_model(ModelEvent(model_name="surya", status="ready"))
   ```

4. Update the inner `report()` function to use the callback Protocol:
   ```python
   def report(stage: str, current: int = 0, total: int = 0):
       if callback:
           callback.on_progress(ProgressEvent(
               phase="surya", current=current, total=total, filename=stage
           ))
       else:
           logger.info(f"{stage}: {current}/{total}" if total else stage)
   ```

5. Remove `from typing import Callable` if it's no longer used elsewhere in the file. Check other usages first.
  </action>
  <verify>
    Run `ruff check src/scholardoc_ocr/pipeline.py src/scholardoc_ocr/processor.py` — no errors.
    Run `python -c "from scholardoc_ocr.pipeline import run_pipeline; import inspect; sig = inspect.signature(run_pipeline); assert 'callback' in sig.parameters, 'callback param missing'"` — passes.
    Run `grep -c 'on_phase\|on_progress\|on_model' src/scholardoc_ocr/pipeline.py` — returns at least 5 (4 on_phase + 1 on_progress; on_model moved to processor.py).
    Run `grep -c 'on_model' src/scholardoc_ocr/processor.py` — returns at least 2 (loading + ready).
  </verify>
  <done>run_pipeline() accepts PipelineCallback, emits PhaseEvent at start/end of both phases, ProgressEvent per file in Phase 1, ModelEvent for Surya loading. processor.py uses PipelineCallback instead of raw Callable.</done>
</task>

<task type="auto">
  <name>Task 2: Add callback integration test</name>
  <files>tests/test_callbacks.py</files>
  <action>
Create tests/test_callbacks.py with these tests:

1. `test_pipeline_callback_protocol_compliance`: Verify LoggingCallback and NullCallback satisfy PipelineCallback Protocol using `isinstance()` check (runtime_checkable).

2. `test_callback_events_collected`: Create a test callback class that appends all events to lists. Construct a minimal PipelineConfig pointing to a temp directory with no files. Call `run_pipeline(config, callback=collector)`. Verify that no events are emitted (no files = early return). This confirms the parameter wiring works without needing real PDFs.

3. `test_default_callback_is_logging`: Patch `LoggingCallback` in pipeline module, call `run_pipeline()` without callback param, verify LoggingCallback was instantiated (using unittest.mock.patch).

4. `test_processor_callback_signature`: Import `PDFProcessor` and use `inspect.signature` to verify `run_surya_batch` has a `callback` parameter (not `progress_callback`).

5. `test_callback_events_fire_during_processing`: Use `unittest.mock.patch` to mock `_process_single` so it returns a fake `ExtendedResult` for one file. Create a PipelineConfig pointing to a temp dir containing one dummy file path (patch `_collect_input_files` to return it). Call `run_pipeline(config, callback=collector)`. Verify collector received: at least 2 PhaseEvent (Phase 1 started + completed), at least 1 ProgressEvent. This tests actual emission without needing real PDFs. Mock at the worker level so the pipeline orchestration (and its callback calls) runs for real.

Use pytest style. Import from `scholardoc_ocr.callbacks` and `scholardoc_ocr.pipeline`.
  </action>
  <verify>
    Run `pytest tests/test_callbacks.py -v` — all tests pass.
    Run `ruff check tests/test_callbacks.py` — no lint errors.
  </verify>
  <done>Test suite proves: Protocol compliance, callback parameter accepted by run_pipeline, default LoggingCallback used, processor uses new signature.</done>
</task>

</tasks>

<verification>
1. `ruff check src/ tests/` — zero errors
2. `pytest tests/ -v` — all tests pass including new callback tests
3. `grep -c "callback" src/scholardoc_ocr/pipeline.py` — confirms callback usage throughout
4. `python -c "from scholardoc_ocr import PipelineCallback, LoggingCallback, NullCallback; print('exports ok')"` — public API still works
</verification>

<success_criteria>
- run_pipeline() has callback parameter with LoggingCallback default
- PhaseEvent emitted at start/end of Tesseract phase and Surya phase (4 emissions minimum)
- ProgressEvent emitted per file completed in Phase 1
- ModelEvent emitted for Surya model loading
- processor.py run_surya_batch uses PipelineCallback instead of Callable
- All existing and new tests pass
- Lint clean
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-and-data-structures/01-04-SUMMARY.md`
</output>
